# ==================================================================
# bpnet9_chipseq.gin
# --------------------------------------------
# model
# [...]

# SeqModel
# [...]

# - Body
# [...]

# - Heads
#   - Profile prediction
# [...]
ProfileHead.loss = @multinomial_nll
ProfileHead.loss_weight = 1
ProfileHead.postproc_fn = @softmax
ProfileHead.use_bias = %use_bias
ProfileHead.bias_input = 'bias/{task}/profile'
ProfileHead.bias_shape = (None, %n_bias_tracks)
ProfileHead.bias_net = @MovingAverages()
MovingAverages.window_sizes = [1, 50]

#      - evaluate
ProfileHead.metric = @PeakPredictionProfileMetric()
PeakPredictionProfileMetric.pos_min_threshold = 0.015
PeakPredictionProfileMetric.neg_max_threshold = 0.005
PeakPredictionProfileMetric.required_min_pos_counts = 2.5
PeakPredictionProfileMetric.binsizes = [1, 2, 5, 10, 50]
# ---------------------
#   - Total count prediction
ScalarHead.target_name = '{task}/counts'
ScalarHead.net = @GlobalAvgPoolFCN()
GlobalAvgPoolFCN.n_tasks = %tracks_per_task
GlobalAvgPoolFCN.n_splines = 0
GlobalAvgPoolFCN.batchnorm = %batchnorm
ScalarHead.loss = 'mse'
# [...]

# --------------------------------------------
# training
train.seed = 42
train.batch_size = 128
train.epochs = 200
train.early_stop_patience = 5
train.num_workers = 16

# --------------------------------------------
# data

# seq_width  -> specified from gin-bindings
# [...]
#bpnet_data.interval_augmentation_shift = 400
bpnet_data.interval_augmentation_shift = 200
bpnet_data.intervals_format = 'bed'

# transform the bias track by aggregating it in a
# sliding window fashion with window sizes of 1 bp (no aggregation) and 50 bp

# specified from the CLI
bpnet_data.dataspec = %dataspec
bpnet_data.seq_width = %seq_width
train.train_epoch_frac = 1.0
train.valid_epoch_frac = 1.0

train.eval_report = @report_template()
report_template.name = 'evaluate.ipynb'

# ============================================
# Macros 
augment_interval = True

lambda = XXX_DYNAMIC_LAMBDA_XXX  # count loss weight 
filters = XXX_DYNAMIC_FILTERS_XXX
tconv_kernel_size = XXX_DYNAMIC_TCONV_XXX
lr = XXX_DYNAMIC_LR_XXX
n_dil_layers = XXX_DYNAMIC_LAYERS_XXX
train.batch_size = XXX_DYNAMIC_BATCH_XXX
batchnorm = False
seq_width = XXX_DYNAMIC_WIDTH_XXX

# TODO - important parameters you might want to adjust
valid_chr = ['chr2', 'chr3', 'chr4']
#valid_chr = ['chr1', 'chr8', 'chr9']
#valid_chr = ['chr5', 'chr6', 'chr7']
#valid_chr = ['chr12', 'chr13', 'chr14']
#test_chr = ['chr1', 'chr8', 'chr9']
test_chr = []
#exclude_chr = ['chrX', 'chrY']
exclude_chr = ['chrM']

# ============================================
# These parameters will be specified from the command line
# (i.e. in `bpnet.cli.train.bpnet_train` function)

# tracks_per_task = 2
# use_bias = True  # set to False if you would like to not use the bias in the model
# n_bias_tracks = 2
# dataspec = 'ChIP-nexus.dataspec.yml'
# tasks = ['Oct4', 'Sox2', 'Nanog', 'Klf4']
